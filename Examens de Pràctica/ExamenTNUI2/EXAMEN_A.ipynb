{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yxgd4zJpz_a6"
   },
   "source": [
    "# Instruccions\n",
    "\n",
    "L'exàmen consta de dos exercicis (4 punts cada un) i una pregunta (2 punts). \n",
    "\n",
    "Per a poder fer els exercicis, heu de descarregar el fitxer `data.csv` i el fitxer `practica2.py` del campus virtual.\n",
    "\n",
    "`IMPORTANT`: Per calcular la semblança entre dos usuaris heu de fer servir le funció `similarity_matrix_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i_6Kxcghz-Lt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "import practica2 as p2\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "num_movies = data.nunique()['movie_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbCC_iO10MT5"
   },
   "source": [
    "### Exercici 1\n",
    "\n",
    "Executa el recomanador (fent servir el mètode `similarity_matrix_2`) per trobar les recomanacions per a un usuari amb `user_id = 123`, que tingui en compte els 150 usuaris més semblants a ell i retorni 5 pel·lícules. Processa la sortida del recomanador (si és necessari) perquè només mostri les pel·lícules que creu que tenen una puntuació superior a 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operacions pesades les faig apart si puc per estalviar temps\n",
    "df_counts = p2.build_counts_table(data)\n",
    "sim_matrix = p2.similarity_matrix_2(df_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92kSompK1wKB",
    "outputId": "9e50b262-f10d-4f10-805e-7da9d56d774c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Babe (1995)', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 'Blade Runner (1982)', 'Citizen Kane (1941)', 'Being John Malkovich (1999)']\n"
     ]
    }
   ],
   "source": [
    "user_id = 123  # usuari per al qual fem les recomanacions\n",
    "\n",
    "# preparem les dades necessaries per a obtenir les recomanacions\n",
    "df_counts = p2.build_counts_table(data)\n",
    "sim_matrix = p2.similarity_matrix_2(df_counts)\n",
    "\n",
    "# cridem al recomandador\n",
    "user_recomendations = p2.getRecommendationsUser(data, user_id, sim_matrix, 5, 150)\n",
    "\n",
    "recomendation_mask = user_recomendations['predicted_score'] > 3.5\n",
    "# filtrem per al rating que se'ns demana\n",
    "recomendations = user_recomendations[recomendation_mask]\n",
    "\n",
    "# calculem la resposta i la mostrem\n",
    "ids = recomendations['movie_id']\n",
    "\n",
    "# Es podria fer més modular amb un for on hi hagues un parametre, s on s= #pelicules i es fes append a names\n",
    "name1 = data[data['movie_id'] == ids[0]]['title'].iloc[0]\n",
    "name2 = data[data['movie_id'] == ids[1]]['title'].iloc[0]\n",
    "name3 = data[data['movie_id'] == ids[2]]['title'].iloc[0]\n",
    "name4 = data[data['movie_id'] == ids[3]]['title'].iloc[0]\n",
    "name5 = data[data['movie_id'] == ids[4]]['title'].iloc[0]\n",
    "names = [name1, name2, name3, name4, name5]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomanacions per l'usuari 123 (Score > 3.5):\n",
      "   movie_id                                              title  \\\n",
      "0        34                                        Babe (1995)   \n",
      "1       750  Dr. Strangelove or: How I Learned to Stop Worr...   \n",
      "2       541                                Blade Runner (1982)   \n",
      "3       923                                Citizen Kane (1941)   \n",
      "4      2997                        Being John Malkovich (1999)   \n",
      "\n",
      "   predicted_score  \n",
      "0         3.974887  \n",
      "1         3.935489  \n",
      "2         3.897483  \n",
      "3         3.876334  \n",
      "4         3.834767  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuració de paràmetres ---\n",
    "target_user_id = 123\n",
    "k_neighbors = 150      # Nombre de veïns a considerar\n",
    "n_recs_requested = 5   # Nombre de recomanacions inicials a demanar\n",
    "min_score = 3.5        # Llindar de tall\n",
    "\n",
    "# --- 2. Càlcul de Matrius ---\n",
    "# Construïm la taula de freqüències/vots\n",
    "df_counts = p2.build_counts_table(data)\n",
    "\n",
    "# Calculem la matriu de similitud fent servir la versió 2 (segons enunciat)\n",
    "sim_matrix = p2.similarity_matrix_2(df_counts)\n",
    "\n",
    "# --- 3. Generació de Recomanacions ---\n",
    "# Cridem la funció per obtenir les prediccions brutes\n",
    "# Assumim que la funció retorna un DataFrame amb columnes ['movie_id', 'predicted_score']\n",
    "raw_recs = p2.getRecommendationsUser(\n",
    "    data, \n",
    "    target_user_id, \n",
    "    sim_matrix, \n",
    "    n_recs_requested, \n",
    "    k_neighbors\n",
    ")\n",
    "\n",
    "# --- 4. Processament: Filtratge i Neteja ---\n",
    "# Pas crític: Filtrem per score > 3.5\n",
    "# Nota: Si el recomanador retorna 5 pel·lícules i cap supera el 3.5, el resultat serà buit.\n",
    "filtered_recs = raw_recs[raw_recs['predicted_score'] > min_score].copy()\n",
    "\n",
    "# Ens assegurem que estiguin ordenades de major a menor puntuació\n",
    "filtered_recs = filtered_recs.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# --- 5. Visualització (Obtenció de Títols) ---\n",
    "# Fem un merge amb el dataset original per recuperar els títols\n",
    "# drop_duplicates() és vital per no duplicar files si 'data' té múltiples entrades per movie_id\n",
    "movies_metadata = data[['movie_id', 'title']].drop_duplicates()\n",
    "\n",
    "final_result = filtered_recs.merge(movies_metadata, on='movie_id', how='left')\n",
    "\n",
    "# Mostrem resultat\n",
    "print(f\"Recomanacions per l'usuari {target_user_id} (Score > {min_score}):\")\n",
    "print(final_result[['movie_id', 'title', 'predicted_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sempre que fas una condició booleana dins un df amb df[condicio] lo de dins és una amscara booleana \n",
    "# (compares una part del df amb una codnició) i agafa totes les dades dels que son true\n",
    "# Les mascares es poden \"sumar\"\n",
    "\n",
    "mask_score = df['score'] > 3.5\n",
    "mask_genre = df['genre'] == 'Terror'\n",
    "final_mask = mask_score & mask_genre  # Combinació lògica\n",
    "\n",
    "filtered = df[final_mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sense .copy(): Pandas et retorna una vista (view) de les dades originals. Si intentes modificar filtered_recs després, Pandas et llançarà el temut SettingWithCopyWarning, perquè no sap si vols modificar el trosretallat o l'original.\n",
    "\n",
    "    Amb .copy(): Forces la creació d'un nou objecte a memòria. A partir d'aquí, filtered_recs és independent i pots modificar-lo sense problemes.\n",
    "\n",
    "    [!tip] Professor's Tip Sempre que creïs un sub-dataframe que pensis modificar més endavant (ordenar, afegir columnes, etc.), posa-hi un .copy() al final. T'estalviaràs molts mals de cap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E22qYWRp9fOO"
   },
   "source": [
    "### Exercici 2\n",
    "\n",
    "Una mètrica alternativa d'evaluació per recomanadors és la **Mean Absolute Percentage Error** (MAPE). Aquesta mètrica es defineix com: \n",
    "\n",
    "$$ MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{A_i - F_i}{A_i} \\right| $$\n",
    "\n",
    "On $A_i$ és el valor real, $F_i$ és el valor pronosticat i n és el nombre total de prediccions.\n",
    "\n",
    "Per aplicar-la, crearem un dataset nou més petit (veure la cel·la de sota). \n",
    "A partir d'aquí:\n",
    "\n",
    "1. Recalcula la matriu de similitud amb aquest nou dataset.\n",
    "2. Divideix el dataset en un conjunt d'entrenament (90%) i un de test (10%).\n",
    "3. Implementa la funció `evaluateRecommendations_mape(train, test, m,n, sim)`\n",
    "4. Avalua el recomanador amb aquesta nova mètrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fem data mes petit agafant users random\n",
    "# Modificat ja que al final hi havia un error, \n",
    "#he fet servir els meus mètodes de la pràctica\n",
    "import random\n",
    "\n",
    "data_ex3 = data.sample(n=500)\n",
    "\n",
    "df_counts_ex3 = p2.build_counts_table(data_ex3)\n",
    "sim_mtx_ex3 = p2.similarity_matrix_2(df_counts_ex3)\n",
    "\n",
    "train_set, test_set = p2.get_sets(data_ex3, 0.1, 42)\n",
    "assert len(test_set) + len(train_set) == len(data_ex3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRecommendations_mape(train, test, m, n, sim):\n",
    "    \"\"\"\n",
    "    Retorna l'error generat pel model (MAPE)\n",
    "\n",
    "    :param DataFrame: dataframe que conté totes les dades\n",
    "    :param userID: usuari respecte al qual fem la recomanació\n",
    "    :param m: nombre d'usuaris que volem per fer la recomanació\n",
    "    :param n: nombre de pelis a retornar\n",
    "    :param sim: matriu de similitud\n",
    "    :return : Escalar (float) corresponent al MAPE (en format decimal, no percentatge)\n",
    "    \"\"\"\n",
    "    # el teu codi aquí\n",
    "    errors = []\n",
    "\n",
    "    # Iterem per cada usuari del test_set\n",
    "    for user_id in test['user_id'].unique():\n",
    "\n",
    "        # Obtenim les recomanacions per l'usuari\n",
    "        recs = p2.getRecommendationsUser(train, user_id, sim, n, m)  # dataframe amb scores\n",
    "        # Agafem les pelis que realment l'usuari ha vist al test\n",
    "        test_user = test[test['user_id'] == user_id]\n",
    "\n",
    "        # Només considerem les pelis que han estat recomanades\n",
    "        merged = pd.merge(test_user, recs, on='movie_id', how='inner', suffixes=('_true', '_pred'))\n",
    "\n",
    "        # Si no hi ha intersecció, saltem aquest usuari\n",
    "        if merged.empty:\n",
    "            continue\n",
    "\n",
    "        # Calcul de l'error absolut\n",
    "        fract_error = merged['rating'] - merged['predicted_score']\n",
    "        fract_error = fract_error/merged['rating']\n",
    "        abs_error = np.abs(fract_error)\n",
    "        errors.extend(abs_error.tolist())\n",
    "\n",
    "    # Mitjana de l'error absolut\n",
    "    mape = np.mean(errors) if errors else np.nan\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea els conjunts de training i de test\n",
    "# S'han creat adalt amb train_set, test_set = p2.get_sets(data_ex3, 0.1, 42)\n",
    "train = train_set\n",
    "test= test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2611 is out of bounds for axis 0 with size 458",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# avaluació\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluateRecommendations_mape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_mtx_ex3\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[150], line 19\u001b[0m, in \u001b[0;36mevaluateRecommendations_mape\u001b[0;34m(train, test, m, n, sim)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Iterem per cada usuari del test_set\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Obtenim les recomanacions per l'usuari\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     recs \u001b[38;5;241m=\u001b[39m \u001b[43mp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetRecommendationsUser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dataframe amb scores\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Agafem les pelis que realment l'usuari ha vist al test\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     test_user \u001b[38;5;241m=\u001b[39m test[test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id]\n",
      "File \u001b[0;32m~/Documentos/ExamenTNUI2/practica2.py:666\u001b[0m, in \u001b[0;36mgetRecommendationsUser\u001b[0;34m(DataFrame, user, sim_mx, n, m)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetRecommendationsUser\u001b[39m(DataFrame: pd\u001b[38;5;241m.\u001b[39mDataFrame, user: \u001b[38;5;28mint\u001b[39m, sim_mx: np\u001b[38;5;241m.\u001b[39mndarray, n: \u001b[38;5;28mint\u001b[39m, m: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    656\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    Retorna un dataframe amb les n pel·lícules més recomanades per a l'usuari.\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;124;03m    :param DataFrame: dataframe que conté totes les dades\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    :return : dataframe de pel·licules amb els scores.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     perdiccions \u001b[38;5;241m=\u001b[39m \u001b[43mweighted_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m perdiccions:\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documentos/ExamenTNUI2/practica2.py:622\u001b[0m, in \u001b[0;36mweighted_average\u001b[0;34m(DataFrame, user, sim_mx, m)\u001b[0m\n\u001b[1;32m    619\u001b[0m df \u001b[38;5;241m=\u001b[39m build_counts_table(DataFrame)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Calculem els m usuaris més semblants al que volem recomanar\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m dicc_top_users \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_users_sim_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dicc_top_users:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/Documentos/ExamenTNUI2/practica2.py:595\u001b[0m, in \u001b[0;36mfind_similar_users_sim_matrix\u001b[0;34m(DataFrame, sim_mx, userID, m)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03mRetorna un diccionari de usuaris similars amb les scores corresponents.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m:param DataFrame: dataframe que conté totes les dades\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m:return : dictionary\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# Agafem la fila de la matriu de similitud\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m serie \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43msim_mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43muserID\u001b[49m\u001b[43m]\u001b[49m, index\u001b[38;5;241m=\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Treiem a l'usuari\u001b[39;00m\n\u001b[1;32m    598\u001b[0m serie \u001b[38;5;241m=\u001b[39m serie\u001b[38;5;241m.\u001b[39mdrop(userID)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2611 is out of bounds for axis 0 with size 458"
     ]
    }
   ],
   "source": [
    "# avaluació\n",
    "evaluateRecommendations_mape(train, test, 50, 5, sim_mtx_ex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "df_counts = p2.build_counts_table(data)\n",
    "sim_matrix = p2.similarity_matrix_2(df_counts)\n",
    "\n",
    "\n",
    "# el teu codi aquí\n",
    "errors = []\n",
    "\n",
    "# Iterem per cada usuari del test_set\n",
    "for user_id in test['user_id'].unique():\n",
    "\n",
    "    # Obtenim les recomanacions per l'usuari\n",
    "    recs = p2.getRecommendationsUser(data, user_id, sim_matrix, 5, 50)  # dataframe amb scores\n",
    "    # Agafem les pelis que realment l'usuari ha vist al test\n",
    "    test_user = test[test['user_id'] == user_id]\n",
    "\n",
    "    # Només considerem les pelis que han estat recomanades\n",
    "    merged = pd.merge(test_user, recs, on='movie_id', how='inner', suffixes=('_true', '_pred'))\n",
    "\n",
    "    # Si no hi ha intersecció, saltem aquest usuari\n",
    "    if merged.empty:\n",
    "        continue\n",
    "\n",
    "    # Calcul de l'error absolut\n",
    "    fract_error = merged['rating'] - merged['predicted_score']\n",
    "    fract_error = fract_error/merged['rating']\n",
    "    abs_error = np.abs(fract_error)\n",
    "    errors.extend(abs_error.tolist())\n",
    "\n",
    "# Mitjana de l'error absolut\n",
    "mape = np.mean(errors) if errors else np.nan\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "\n",
    "Com s'interpreten un MAE i un MAPE de 0.5 en el context del nostre recomanador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resposta:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Com s'interpreten per separat\n",
    "\n",
    "    Amb la Mape vas sumant, percentualment, què tant semblants són els predicted ratings, és a dir, com valores aquesta recomanació, que tant aprop està de ser la valoració exacte\n",
    "\n",
    "\n",
    "    Amb la MAE vas sumant què tant diferents són, però simplement fas la diferencia, és a dir, quants \"punts\" t'has allunyat de la resposta correcta\n",
    "\n",
    "- Com s'interpreta el resultat\n",
    "\n",
    "  \n",
    "    Amb un 0'5 de MAE trobem que nomes ens allunyem en 0,5 punts de les dades reals (de mitjana\n",
    "\n",
    "\n",
    "    Amb un 0'5 de MAPE trobem que les dades nomes s'assemblen a les reals en un 50% (de mitjana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
